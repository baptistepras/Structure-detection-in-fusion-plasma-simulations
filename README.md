# Structure Detection in Fusion Plasma Simulations

A complete machine learning pipeline for detecting blob structures in fusion plasma simulation videos, developed as a solution for a Codabench competition. The solution combines YOLOv8 object detection with an MLP post-filter and pseudo-labeling to achieve high precision and recall on density field videos.

## Overview

This project implements an advanced blob detection system for fusion plasma simulations by:
- Training a **YOLOv8n** detector on annotated density field frames
- Using **pseudo-labeling** to leverage unlabeled data
- Applying an **MLP post-filter** to reduce false positives while maintaining high recall
- Supporting multiple color modes and data augmentation strategies

## Problem Statement

The challenge is to detect and localize blob-like structures (coherent plasma regions) in time-series density field data from fusion plasma simulations. These structures are important for understanding plasma turbulence and transport phenomena. The dataset consists of:
- **30 annotated images** with ground truth bounding boxes
- **8 unlabeled images** for semi-supervised learning
- Grayscale density field data stored in HDF5 format

## Solution Approach

### Architecture

The solution uses a **two-stage detection pipeline**:

1. **YOLO Detector (Stage 1)**: YOLOv8n trained to detect blob regions with high recall
2. **MLP Post-Filter (Stage 2)**: Lightweight neural network that filters false positives using:
   - Intensity-based statistics (mean, std, min, max)
   - Histogram of gradients (Sobel gradients)
   - Geometric features from grayscale patches
   - Ring region analysis for context

### Training Pipeline

The training follows a **two-round approach**:

#### Round 1: Initial Training
1. Train YOLOv8n on 30 annotated images with augmentation
2. Train MLP post-filter on synthetic positive/negative boxes generated by jittering ground truth boxes

#### Round 2: Pseudo-Labeling
1. Use Round-1 YOLO + MLP to predict boxes on 8 unlabeled images
2. Select top-k most confident predictions per image (ranked by MLP probability)
3. Retrain YOLO on combined dataset (30 labeled + 8 pseudo-labeled = 38 images)

### Key Features

- **Grayscale Color Mode**: Optimized for single-channel density data
- **Data Augmentation**: Moderate augmentation with mosaic and mixup
- **MLP Feature Engineering**: 
  - Box patch statistics (mean, std, min, max, entropy)
  - Sobel gradient histograms (8 directional bins)
  - Laplacian sharpness metrics
  - Ring region context (outer annulus statistics)
- **Hard Negative Mining**: MLP trained with challenging negative examples at various IoU thresholds

## Installation

### Requirements

```bash
# Python 3.10+
pip install torch torchvision
pip install ultralytics  # YOLOv8
pip install opencv-python
pip install h5py
pip install numpy
pip install pillow
pip install pyyaml
```

### Dependencies

- **PyTorch**: Deep learning framework
- **Ultralytics**: YOLOv8 implementation
- **OpenCV**: Image processing
- **h5py**: HDF5 file handling
- **NumPy**: Numerical computing

## Usage

### Training

The main entry point is the `train_model()` function, which follows the Codabench API:

```python
from submission import train_model

# Train the model (expects Codabench-style training directory)
model = train_model(training_dir="path/to/training/data")
```

### Inference

The trained model is wrapped in a `YOLOWrapper` that implements `torch.nn.Module`:

```python
import torch

# Model expects (C, H, W) tensors where C=1 for grayscale density data
density_tensor = torch.randn(1, 512, 512)  # Example input

# Forward pass returns list of detection dictionaries
predictions = model(density_tensor)

# Each prediction dict contains:
# - 'boxes': (N, 4) tensor of [x1, y1, x2, y2] coordinates
# - 'scores': (N,) tensor of confidence scores
# - 'labels': (N,) tensor of class labels (all 0 for 'blob')
```

### Data Format

Training data should follow this structure:
```
training_dir/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ annotated/          # 30 labeled images
â”‚   â”‚   â”‚   â”œâ”€â”€ video_001.h5
â”‚   â”‚   â”‚   â”œâ”€â”€ video_001.xml   # Pascal VOC annotations
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ unlabeled/          # 8 unlabeled images
â”‚   â”‚       â”œâ”€â”€ video_031.h5
â”‚   â”‚       â””â”€â”€ ...
```

HDF5 files contain density field arrays, and XML files follow Pascal VOC format for bounding box annotations.

## Configuration

### YOLO Configurations

The implementation supports multiple configurations (see `CONFIGS` dict):

**Config c02 (Final)**: YOLOv8n with grayscale mode and moderate augmentation
```python
{
    'model_ckpt': 'yolov8n.pt',
    'color_mode': 'gray',
    'infer': {'conf': 0.01, 'iou': 0.50, 'max_det': 300},
    'aug': {
        'fliplr': 0.0,
        'flipud': 0.2,
        'scale': 0.2,
        'translate': 0.08,
        'degrees': 5.0,
        'mosaic': 0.1,
        'mixup': 0.05,
    },
    'yolo': {'batch': 8, 'epochs': 1000, 'patience': 30}
}
```

### MLP Configuration

```python
{
    'hidden': (256,),           # Hidden layer sizes
    'dropout': 0.1,             # Dropout rate
    'lr': 0.002,                # Learning rate
    'wd': 0.0001,               # Weight decay
    'batch': 128,               # Batch size
    'epochs': 200,              # Max epochs
    'patience': 12,             # Early stopping patience
    'mlp_threshold': 0.7,       # Inference threshold
    'hi_neg_iou': 0.35,         # High-IoU negative examples
    'lo_neg_iou': 0.05,         # Low-IoU negative examples
    'pos_iou': 0.5,             # Positive example threshold
    'n': 5                      # Jitter samples per GT box
}
```

### Changing Configuration

To use a different config, modify `CONFIG_ID` in `submission.py`:
```python
CONFIG_ID = "c02"  # Use c01 or c02
```

## Model Architecture

### YOLOv8n Backbone
- **Input**: 512Ã—512 RGB images (grayscale density converted to RGB)
- **Architecture**: YOLOv8-nano for efficiency on small datasets
- **Output**: Bounding boxes with confidence scores

### MLP Post-Filter
- **Input**: Feature vector (34 dimensions) extracted from each YOLO detection
- **Architecture**: 
  - Input layer (34 features)
  - Hidden layer (256 neurons, ReLU activation, 10% dropout)
  - Output layer (1 neuron, sigmoid activation)
- **Output**: Probability that box contains a true blob

### Feature Extraction (34 features)

1. **Box Patch Statistics (5 features)**:
   - Mean intensity, std, min, max, entropy

2. **Sobel Gradient Histogram (8 features)**:
   - Directional gradient bins (0Â°, 45Â°, 90Â°, 135Â°, 180Â°, 225Â°, 270Â°, 315Â°)

3. **Laplacian Statistics (5 features)**:
   - Mean, std, min, max, entropy of sharpness

4. **Normalized Coordinates (2 features)**:
   - Center position (cx, cy) normalized by image size

5. **Ring Region Statistics (14 features)**:
   - Same stats as box patch but for outer annular region (1.6Ã— box size)
   - Provides contextual information around the detection

## Training Details

### Data Augmentation
- **Vertical flip**: 20% probability
- **Scale**: Â±20% random scaling
- **Translation**: Â±8% random translation
- **Rotation**: Â±5 degrees
- **Mosaic**: 10% (combines 4 images)
- **Mixup**: 5% (blends 2 images)

### Synthetic Data Generation for MLP

For each ground truth box:
1. Generate 5 positive jittered boxes (IoU â‰¥ 0.5 with GT)
2. Generate 5 high-IoU negative boxes (0.05 < IoU < 0.35)
3. Generate 5 low-IoU negative boxes (IoU < 0.05)

This creates a balanced dataset with hard negative examples.

### Pseudo-Labeling Strategy

- **Top-k selection**: Keep top 40 boxes per unlabeled image
- **Ranking**: Sort by MLP probability (not YOLO confidence)
- **Rationale**: MLP learns blob characteristics better than YOLO confidence

## Results and Performance

The final model (Config c02) achieves:
- **High Recall**: Detects most blob structures due to aggressive YOLO detection
- **High Precision**: MLP filter removes false positives effectively
- **Robustness**: Pseudo-labeling improves generalization to unlabeled data

### Inference Pipeline

1. Convert density tensor to grayscale uint8
2. YOLO predicts boxes with low confidence threshold (0.01)
3. YOLO NMS removes duplicates (IoU threshold 0.50)
4. MLP filters boxes (threshold 0.7)
5. Return final detections on CPU

## Development History

### Successful Approaches
âœ… Grayscale color mode (vs. physics-inspired colormaps)  
âœ… Moderate augmentation with mosaic/mixup  
âœ… MLP post-filtering with engineered features  
âœ… Pseudo-labeling with top-k selection  
âœ… Two-round training strategy  

### Attempted but Not Improved
âŒ Larger YOLO models (yolov8s/m/l, yolov11n) - overfitting on small dataset  
âŒ Alternative color modes (plasma, physics-inspired) - grayscale was optimal  
âŒ Self-supervised pre-training with VAE - no benefit on small, specific dataset  
âŒ Synthetic data generation via inpainting - poor quality synthetics  
âŒ Combined YOLO+MLP confidence scoring - MLP alone was better  

## Files

- **submission.py**: Main implementation (1664 lines)
  - YOLO training and inference
  - MLP post-filter
  - Pseudo-labeling pipeline
  - Feature extraction
  - Data conversion utilities
- **yolo_train_mosaic.png**: Example of mosaic augmentation during training
- **README.md**: This file

## Technical Notes

### Device Compatibility
- Supports CUDA, MPS (Apple Silicon), and CPU
- Inference returns CPU tensors to avoid device mismatches

### Memory Management
- Uses `/tmp` for temporary YOLO datasets
- Cleans up previous runs automatically

### Code Organization
- **Lines 1-75**: Imports and global configuration
- **Lines 77-189**: Configuration management
- **Lines 191-362**: YOLOWrapper (Codabench-compatible model)
- **Lines 364-418**: Image processing utilities
- **Lines 419-709**: YOLO training and pseudo-labeling
- **Lines 711-792**: Bounding box utilities
- **Lines 794-1168**: MLP feature extraction
- **Lines 1169-1469**: MLP dataset and training
- **Lines 1471-1664**: Main training pipeline

## Author

**Baptiste PRAS**  
ðŸ“§ baptiste.pras@universite-paris-saclay.fr  
ðŸ“… February 2026

## License

This code was developed for the Codabench competition on structure detection in fusion plasma simulations.

---

*Developed as part of a machine learning competition for fusion plasma physics research.*
